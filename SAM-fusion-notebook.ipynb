{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b7e71cd-bfd2-453a-bc54-253a01a2885b",
   "metadata": {},
   "source": [
    "# <b>Deep Learning:</b>\n",
    "# Improving existing segmentators performance with zero-shot segmentators\n",
    "\n",
    "This Notebook implements the code used in our paper \"Improving existing segmentators performance with zero-shot segmentators\".\n",
    "\n",
    "In our study, we used the predicted segmentation masks from state-of-the-art methods **DeepLabV3+** https://github.com/VainF/DeepLabV3Plus-Pytorch and **PVTv2** https://github.com/whai362/PVT.\n",
    "\n",
    "From these masks, we produce some checkpoints to feed **SAM** (**Segment Anything**, https://github.com/facebookresearch/segment-anything) for *Post-Processing Segmentation Enhancement* or SEEM (**Segment Everything Everywhere All at Once**, https://github.com/UX-Decoder/Segment-Everything-Everywhere-All-At-Once) models.\n",
    "\n",
    "The **Segment Anything Model (SAM)** produces high quality object masks from input prompts such as points or boxes, and it can be used to generate masks for all objects in an image. It has been trained on a dataset of 11 million images and 1.1 billion masks, and has strong zero-shot performance on a variety of segmentation tasks.\n",
    "\n",
    "Similarly to SAM, **Segment Everything Everywhere All at Once (SEEM)** allows users to easily segment an image using prompts of different types including visual prompts (points, marks, boxes, scribbles and image segments) and language prompts (text and audio), etc. It can also work with any combinations of prompts or generalize to custom prompts.\n",
    "\n",
    "\n",
    "We devised 4 different methods for producing checkpoints:\n",
    " - A: the pixel whose coordinates are, along each dimension, the average of value of all the mask's pixels coordinate\n",
    " - B: the center of mass of the mask\n",
    " - C: one (or more) pixels drawn (uniformly or not...) randomly inside the mask area\n",
    " - D: pixels drawn from the intersection of a uniform grid of fixed step size and the mask. \"b\" stands for the intersection between the grid and the eroded mask, where the mask is shrinked of 10 pixels.\n",
    "---\n",
    "\n",
    "### In order to run the script, you need to:\n",
    " - set the path to your data folder    (in \"Parameters of the script\" cell)\n",
    " - prepare the dataset in this folder structure:\n",
    "\n",
    "~~~\n",
    "    ├── dataset\n",
    "        ├── name of dataset\n",
    "        │   ├── imgs                    # rgb source images\n",
    "        │   ├── gt                      # gt segmentation images\n",
    "        │   └── segmentator_deeplab     # example of segmentator source: deeplab\n",
    "                                        # in this folder you must put\n",
    "                                        #   - .png images (segmentator's output logits)\n",
    "                                        #   - .bmp images (segmentator's output binary mask)\n",
    "        └── ...\n",
    "~~~\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33681dd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b28288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch                    ## pip install torch\n",
    "import matplotlib.pyplot as plt ## pip install matplotlib\n",
    "import cv2                      ## pip install opencv-python\n",
    "from skimage import measure     ## pip install scikit-image\n",
    "from scipy import ndimage       ## pip install scipy\n",
    "import scipy.io\n",
    "from tqdm import tqdm           ## pip install tqdm\n",
    "\n",
    "import numpy as np              ## pip install numpy\n",
    "import pickle                   ## pip install pickle\n",
    "\n",
    "import os,glob\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "###\n",
    "## to download SAM:\n",
    "## git clone git@github.com:facebookresearch/segment-anything.git\n",
    "## cd segment-anything; pip install -e .\n",
    "###\n",
    "\n",
    "from segment_anything import sam_model_registry, SamPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c816367-81a6-4315-9ccb-96ec3deee17c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### For reproducibility, seed of random generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8172464a-1488-4efe-b203-a0787a38ac5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2dd0f8-7e1e-448c-a584-218407de8fa1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Helper function for reading images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273acfef-c074-4180-a698-af4eeb6472a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_img(path:str) -> np.ndarray:\n",
    "    return cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def read_bmask(path:str) -> np.ndarray:\n",
    "    return cv2.imread(path, cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "\n",
    "def read_rmask(path:str) -> np.ndarray:\n",
    "    return cv2.imread(path, cv2.IMREAD_UNCHANGED) \n",
    "\n",
    "def get_data(paths:list) -> list:\n",
    "    img_path, gt_mask_path, dplabv3_bmask_path, dplabv3_rmask_path = paths\n",
    "    img           = read_img(img_path)\n",
    "    gt_mask       = read_bmask(gt_mask_path)\n",
    "    dplabv3_bmask = read_bmask(dplabv3_bmask_path)\n",
    "    dplabv3_rmask = read_rmask(dplabv3_rmask_path)\n",
    "    assert img.shape[:2] == gt_mask.shape == \\\n",
    "           dplabv3_bmask.shape == dplabv3_rmask.shape[:2], \\\n",
    "            f\"Error: shape mismatch, {img.shape[:2]} {gt_mask.shape} {dplabv3_bmask.shape} {dplabv3_rmask.shape[:2]}\"\n",
    "    return img, gt_mask, dplabv3_bmask, dplabv3_rmask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db97b748-00f1-4024-b597-8a7fc55f2c90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Helper functions for displaying points, boxes, and masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc90d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_mask(mask: np.ndarray, ax, random_color:bool=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords:np.ndarray, labels:np.ndarray, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25) # this is if you want the star\n",
    "    #ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=10, edgecolor='green', linewidth=1.25) # this is if you want the dot\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n",
    "\n",
    "def draw_img(img:np.ndarray, input_point:np.ndarray=None, input_label:np.ndarray=None, \\\n",
    "             mask: np.ndarray=None, title:plt.title = None, plt_show:bool=True):\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(img)\n",
    "    if mask is not None:\n",
    "        show_mask(mask, plt.gca())\n",
    "    if input_point is not None and input_label is not None:\n",
    "        show_points(input_point, input_label, plt.gca())\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=18)\n",
    "    plt.axis('off')\n",
    "    if plt_show:\n",
    "        plt.show()\n",
    "        \n",
    "def draw_results(masks:list, scores:list, gt_mask:np.ndarray, \\\n",
    "                 input_point:np.ndarray, input_label:np.ndarray):\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        iou = get_iou(mask, gt_mask)\n",
    "        title = f\"Mask {i+1}, Score: {score:.3f}, IoU: {iou:.3f}\"\n",
    "        draw_img(img, input_point, input_label, mask, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6383e2-8be2-4582-a379-8bf1ecb9b7e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Helper function for computing how many blobs a mask contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ed7f4-c63a-41a9-b6a2-db248a0e01c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_mask_of_blobs(mask: np.ndarray) -> np.ndarray:\n",
    "    # compute how many blobs a mask contains\n",
    "    # @return: a mask in which each pixel is assigned a blob ID\n",
    "    mask_of_blobs = measure.label(mask)\n",
    "    return mask_of_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcec3e38-b9d2-495a-b517-741c5d9b4f1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Helper function for logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc412018-e932-4f92-b8ed-05992cb6a731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log(paths: tuple):\n",
    "    img_path, gt_mask_path, dplabv3_bmask_path, dplabv3_rmask_path = paths\n",
    "    print(\"img_path          :\", img_path)\n",
    "    print(\"gt_mask_path      :\", gt_mask_path)\n",
    "    print(\"dplabv3_bmask_path:\", dplabv3_bmask_path)\n",
    "    print(\"dplabv3_rmask_path:\", dplabv3_rmask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed309f-323d-4899-a693-143245e7e580",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Metrics\n",
    "(between a predicted mask and a Ground Truth mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc14670-2a29-47a5-9bed-3fc4ecd1c80f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "class Metrics():\n",
    "    eps=np.finfo(np.double).eps\n",
    "    \n",
    "    def reset(self):\n",
    "        self.ious, self.maes, self.dices, self.wfms, self.emes = [], [], [], [], []\n",
    "        self.tps, self.fps, self.tns, self.fns = 0, 0, 0, 0\n",
    "    \n",
    "    def step_common(self, pred, GT):\n",
    "        iou       = self.get_iou(pred, GT)\n",
    "        dice      = self.get_dice(pred, GT)\n",
    "        mae       = self.compute_mae(pred, GT)\n",
    "        fscore    = self.FbetaMeasure(pred.astype(bool), GT.astype(bool))\n",
    "        e_measure = self.EMeasure(pred.astype(bool), GT.astype(bool))\n",
    "        self.ious.append(iou)\n",
    "        self.dices.append(dice)\n",
    "        self.maes.append(mae)\n",
    "        self.wfms.append(fscore)\n",
    "        self.emes.append(e_measure)\n",
    "    \n",
    "    def step_skin(self, pred, gt):\n",
    "        y_pred_bool = pred.astype(bool)\n",
    "        y_true_bool = gt.astype(bool)\n",
    "        self.tps += np.logical_and(y_true_bool, y_pred_bool).sum()\n",
    "        self.tns += np.logical_and(~y_true_bool, ~y_pred_bool).sum()\n",
    "        self.fps += np.logical_and(~y_true_bool, y_pred_bool).sum()\n",
    "        self.fns += np.logical_and(y_true_bool, ~y_pred_bool).sum()\n",
    "        \n",
    "        \n",
    "    def step_locuste(self, pred, GT):\n",
    "        iou       = self.get_iou_locuste(pred, GT)\n",
    "        dice      = self.get_dice_locuste(pred.astype(bool), GT.astype(bool))\n",
    "        mae       = self.compute_mae(pred, GT)\n",
    "        e_measure = self.EMeasure(pred.astype(bool), GT.astype(bool))\n",
    "        fscore    = self.FbetaMeasure(pred.astype(bool), GT.astype(bool))\n",
    "        self.ious.append(iou)\n",
    "        self.dices.append(dice)\n",
    "        self.maes.append(mae)\n",
    "        self.wfms.append(fscore)\n",
    "        self.emes.append(e_measure)\n",
    "        \n",
    "    \n",
    "    def get_iou_common(self, pred, gt, beta=1):\n",
    "        y_pred_bool = pred.astype(bool)\n",
    "        y_true_bool = gt.astype(bool)\n",
    "        tp = np.logical_and(y_true_bool, y_pred_bool).sum()\n",
    "        tn = np.logical_and(~y_true_bool, ~y_pred_bool).sum()\n",
    "        fp = np.logical_and(~y_true_bool, y_pred_bool).sum()\n",
    "        fn = np.logical_and(y_true_bool, ~y_pred_bool).sum()\n",
    "        if tp+fn+fp==0:\n",
    "            if tp==0:\n",
    "                iou=1.0\n",
    "            else:\n",
    "                iou=0.0\n",
    "        else:\n",
    "            iou = tp / (tp + fn + fp)\n",
    "\n",
    "        return iou\n",
    "\n",
    "    def get_iou_locuste(self, pred, target):\n",
    "        return jaccard_score(target.reshape(-1).astype(bool), pred.reshape(-1).astype(bool))\n",
    "\n",
    "    def get_dice_common(self, pred, gt):\n",
    "        y_pred_bool = pred.astype(bool)\n",
    "        y_true_bool = gt.astype(bool)\n",
    "\n",
    "        tp = np.logical_and( y_true_bool,  y_pred_bool).sum()\n",
    "        tn = np.logical_and(~y_true_bool, ~y_pred_bool).sum()\n",
    "        fp = np.logical_and(~y_true_bool,  y_pred_bool).sum()\n",
    "        fn = np.logical_and( y_true_bool, ~y_pred_bool).sum()\n",
    "        \n",
    "        if tp+fn+fp==0:\n",
    "            dice=1.0 if tp==0 else 0.0\n",
    "        else:\n",
    "            dice = 2*tp / (2*tp + fn + fp)\n",
    "\n",
    "        return dice\n",
    "\n",
    "    def _calConfusion(self, pred, GT):\n",
    "        TP=np.sum(pred[GT]==1)\n",
    "        FP=np.sum(pred[~GT]==1)\n",
    "        TN=np.sum(pred[~GT]==0)\n",
    "        FN=np.sum(pred[GT]==0)\n",
    "        return TP,FP,TN,FN\n",
    "\n",
    "    def get_dice_locuste(self, y_pred, y_true):\n",
    "        # True Positive (TP): we predict a label of 1 (positive), and the true label is 1.\n",
    "        y_true_bool = y_true.astype(bool)\n",
    "        y_pred_bool = y_pred.astype(bool)\n",
    "\n",
    "        tp = np.logical_and(y_true_bool, y_pred_bool).sum()\n",
    "        tn = np.logical_and(~y_true_bool, ~y_pred_bool).sum()\n",
    "        fp = np.logical_and(~y_true_bool, y_pred_bool).sum()\n",
    "        fn = np.logical_and(y_true_bool, ~y_pred_bool).sum()\n",
    "        return (2.0 * tp) / (2.0 * tp + fp + fn + 1e-7)#, tp, tn, fp, fn\n",
    "\n",
    "    def compute_mae(self, pred: np.ndarray, gt: np.ndarray) -> np.ndarray:\n",
    "        mae = np.mean(np.abs(pred - gt))\n",
    "        return mae\n",
    "    \n",
    "    ## F-Measure\n",
    "    def FbetaMeasure(self, pred, GT, beta= math.sqrt(0.3)):\n",
    "        TP,FP,TN,FN=self._calConfusion(pred, GT)\n",
    "        if TP+FN+FN==0:\n",
    "            if TP==0:\n",
    "                Fbeta=1.0\n",
    "            else:\n",
    "                Fbeta=0.0\n",
    "        else:\n",
    "            P=TP/(TP+FP+1e-8) #precision\n",
    "            R=TP/(TP+FN+1e-8) #recall\n",
    "            Fbeta=(beta**2+1)*P*R/((beta**2)*P+R+1e-8)\n",
    "        return Fbeta\n",
    "    \n",
    "    ## E-Measure\n",
    "    def _EnhancedAlignmnetTerm(self, align_Matrix):\n",
    "        enhanced=((align_Matrix+1)**2)/4\n",
    "        return enhanced\n",
    "\n",
    "    def _AlignmentTerm(self, dGT, dpred):\n",
    "        mean_dpred=np.mean(dpred)\n",
    "        mean_dGT=np.mean(dGT)\n",
    "        align_dpred=dpred-mean_dpred\n",
    "        align_dGT=dGT-mean_dGT\n",
    "        align_matrix=2*(align_dGT*align_dpred)/(align_dGT**2+align_dpred**2+self.eps)\n",
    "        return align_matrix\n",
    "\n",
    "    def EMeasure(self, pred, GT):\n",
    "        dGT,dpred=GT.astype(np.float64),pred.astype(np.float64)\n",
    "        if np.sum(GT)==0:#completely black\n",
    "            enhanced_matrix=1-dpred\n",
    "        elif np.sum(~GT)==0:\n",
    "            enhanced_matrix=dpred\n",
    "        else:\n",
    "            align_matrix=self._AlignmentTerm(dGT,dpred)\n",
    "            enhanced_matrix=self._EnhancedAlignmnetTerm(align_matrix)\n",
    "        rows,cols= GT.shape\n",
    "        \n",
    "        # score=np.sum(enhanced_matrix)/(rows*cols-1+self.eps)\n",
    "        score=np.sum(enhanced_matrix)/(rows*cols+self.eps)\n",
    "        return score\n",
    "    \n",
    "    def get_results_common(self) -> (float, float, float, float, float):\n",
    "        return np.array(self.ious).mean(), np.array(self.dices).mean(), np.array(self.maes).mean(), np.array(self.wfms).mean(), np.array(self.emes).mean()\n",
    "\n",
    "    def get_results_skin(self):\n",
    "        iou = self.tps / (self.tps + self.fns + self.fps)\n",
    "        dice = (2.0 * self.tps) / (2.0 * self.tps + self.fps + self.fns + 1e-7)\n",
    "        # for skin dataset, we didn't need the other metrics. TODO: implement\n",
    "        return iou, dice, None, None, None\n",
    "    \n",
    "    def set_mode_locuste(self):\n",
    "        self.step = self.step_locuste\n",
    "        self.get_iou = self.get_iou_locuste\n",
    "        self.get_dice = self.get_dice_locuste\n",
    "    \n",
    "    def set_mode_skin(self):\n",
    "        self.step = self.step_skin\n",
    "        self.get_results = self.get_results_skin\n",
    "        \n",
    "    def __init__(self, dataset=None):\n",
    "        self.reset()\n",
    "        self.step        = self.step_common\n",
    "        self.get_iou     = self.get_iou_common\n",
    "        self.get_dice    = self.get_dice_common\n",
    "        self.get_results = self.get_results_common\n",
    "        if \"SKIN\" in dataset:\n",
    "            self.set_mode_skin()\n",
    "        elif \"Locuste\" in dataset:\n",
    "            self.set_mode_locuste()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ea858-a464-46d9-9e9d-294296946908",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Functions for the sampling of the checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e648b45-3339-4e12-9ee8-4ed782671660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Sampler:\n",
    "    verbose = True\n",
    "    sampling_step = None\n",
    "    min_blob_count = None\n",
    "    def __init__(self, verbose, sampling_step, min_blob_count):\n",
    "        self.verbose        = verbose\n",
    "        self.sampling_step  = sampling_step\n",
    "        self.min_blob_count = min_blob_count\n",
    "    \n",
    "    def sample_pixels(self, mask_of_blobs: np.ndarray, mask: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "        # draw a pix for each blob\n",
    "        input_point, input_label = [], []\n",
    "        blob_labels, blob_sample = np.unique(mask_of_blobs, return_index=True)\n",
    "        gt_fl = mask.flatten()\n",
    "        for bl, bs in zip(blob_labels, blob_sample):\n",
    "            mask_bool = (mask_of_blobs==bl)\n",
    "            count = mask_bool.sum()\n",
    "            if gt_fl[bs]>=1.0 and count>self.min_blob_count: ## it's not a background blob or a false blob\n",
    "                x_center, y_center = np.argwhere(mask_bool).sum(0)/count\n",
    "                x_center, y_center = int(x_center) % mask.shape[0], int(y_center) % mask.shape[1]\n",
    "                input_point.append([y_center, x_center])\n",
    "                input_label.append(1)\n",
    "                print(f\"blob #{bl} drawn point: {[x_center, y_center]}\") if self.verbose else None\n",
    "\n",
    "        # no mask? pick the center pixel of image\n",
    "        if len(input_point) == 0:\n",
    "            input_point, input_label = [[mask.shape[1]//2, mask.shape[0]//2]], [1]\n",
    "\n",
    "        return np.array(input_point), np.array(input_label)\n",
    "    \n",
    "    def sample_pixels_center_of_mass(self, mask_of_blobs: np.ndarray, mask: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "        # draw a pix for each blob\n",
    "        input_point, input_label = [], []\n",
    "        blob_labels, blob_sample = np.unique(mask_of_blobs, return_index=True)\n",
    "        gt_fl = mask.flatten()\n",
    "        for bl, bs in zip(blob_labels, blob_sample):\n",
    "            mask_bool = (mask_of_blobs==bl)\n",
    "            count = mask_bool.sum()\n",
    "            if gt_fl[bs]>=1.0 and count>self.min_blob_count: ## it's not a background blob or a false blob\n",
    "                x_center, y_center = ndimage.center_of_mass(mask_bool)\n",
    "                input_point.append([y_center, x_center])\n",
    "                input_label.append(1)\n",
    "                print(f\"blob #{bl} drawn point: {[x_center, y_center]}\") if self.verbose else None\n",
    "\n",
    "        # no mask? pick the center pixel of image\n",
    "        if len(input_point) == 0:\n",
    "            input_point, input_label = [[mask.shape[1]//2, mask.shape[0]//2]], [1]\n",
    "            print(f\"empty blob -> {input_point}\") if self.verbose else None\n",
    "\n",
    "        return np.array(input_point), np.array(input_label)\n",
    "\n",
    "    def sample_pixels_random(self, mask_of_blobs: np.ndarray, mask: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "        # draw a pix for each blob\n",
    "        input_point, input_label = [], []\n",
    "        blob_labels, blob_sample = np.unique(mask_of_blobs, return_index=True)\n",
    "        gt_fl = mask.flatten()\n",
    "        for bl, bs in zip(blob_labels, blob_sample):\n",
    "            mask_bool = (mask_of_blobs==bl)\n",
    "            count = mask_bool.sum()\n",
    "            if gt_fl[bs]>=1.0 and count>self.min_blob_count: ## it's not a background blob or a false blob\n",
    "                indices = np.argwhere(mask_bool)\n",
    "                random_index = np.random.choice(indices.shape[0])\n",
    "                x_center, y_center = indices[random_index]\n",
    "                input_point.append([y_center, x_center])\n",
    "                input_label.append(1)\n",
    "                print(f\"blob #{bl} drawn point: {[x_center, y_center]}\") if self.verbose else None\n",
    "\n",
    "        # no mask? sample a random point\n",
    "        if len(input_point) == 0:\n",
    "            input_point, input_label = [                 [np.random.randint(0, mask.shape[1]),                    np.random.randint(0, mask.shape[0])]],             [1]\n",
    "\n",
    "        return np.array(input_point), np.array(input_label)\n",
    "\n",
    "    def get_grid(self, mask, offset_px_x, offset_px_y):\n",
    "        row = np.zeros(mask.shape, dtype=int)\n",
    "        col = np.zeros(mask.shape, dtype=int)\n",
    "\n",
    "        for i in range(offset_px_y, row.shape[0], self.sampling_step):\n",
    "            row[i, :] = 1\n",
    "        for i in range(offset_px_x, col.shape[1], self.sampling_step):\n",
    "            col[:, i] = 1\n",
    "        res = row & col\n",
    "        return res\n",
    "    \n",
    "    def sample_pixels_grid(self, mask_of_blobs: np.ndarray, mask: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "\n",
    "        res = self.get_grid(mask, 0, 0)\n",
    "\n",
    "        input_point = np.argwhere(res & mask.astype(np.int64))\n",
    "        input_point[:, (0, 1)] = input_point[:, (1, 0)]\n",
    "\n",
    "        input_label = [1 for _ in input_point]\n",
    "        \n",
    "        return np.array(input_point), np.array(input_label)\n",
    "    \n",
    "    def sample_pixels_eroded_grid(self, mask_of_blobs: np.ndarray, mask: np.ndarray) -> (np.ndarray, np.ndarray):\n",
    "        \n",
    "        input_point = []\n",
    "        offset_px_x = 0\n",
    "        offset_px_y = 0\n",
    "        \n",
    "        while len(input_point)==0 and offset_px_y < self.sampling_step:\n",
    "            res = self.get_grid(mask, offset_px_x, offset_px_y)\n",
    "            erode_size = 10\n",
    "        \n",
    "            while True:\n",
    "                # Erode the mask\n",
    "                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (erode_size, erode_size))\n",
    "                eroded_mask = cv2.erode(mask.astype('uint8'), kernel)\n",
    "\n",
    "                input_point = np.argwhere(res & eroded_mask.astype(np.int64))\n",
    "                input_point[:, (0, 1)] = input_point[:, (1, 0)]\n",
    "\n",
    "                blob_labels, blob_sample = np.unique(mask_of_blobs, return_index=True)\n",
    "                gt_fl = mask.flatten()\n",
    "\n",
    "                blobs = np.zeros(blob_labels.shape[0], dtype=np.float32)\n",
    "                for i, (bl, bs) in enumerate(zip(blob_labels, blob_sample)):\n",
    "                    mask_bool = (mask_of_blobs==bl)\n",
    "                    count = mask_bool.sum()\n",
    "                    if not (gt_fl[bs]>=1.0 and count>self.min_blob_count): ## it's not a background blob or a false blob\n",
    "                        blobs[i] = -1\n",
    "\n",
    "                for i in range(input_point.shape[0]):\n",
    "                    fl_ip = input_point[i][0]*mask.shape[1] + input_point[i][1]\n",
    "                    idx = mask_of_blobs[input_point[i][1], input_point[i][0]]\n",
    "                    blobs[idx]=1.0\n",
    "                \n",
    "                if not np.any(blobs==0.0) or erode_size==1:\n",
    "                    break\n",
    "                erode_size -= 1\n",
    "            \n",
    "            offset_px_x += 1\n",
    "            if offset_px_x>self.sampling_step:\n",
    "                offset_px_x = 0\n",
    "                offset_px_y += 1\n",
    "            \n",
    "        \n",
    "        input_label = [1 for _ in input_point]\n",
    "\n",
    "        # still no mask? sample a random point\n",
    "        if len(input_point) == 0:\n",
    "            return self.sample_pixels_grid(mask_of_blobs, mask)\n",
    "\n",
    "        return np.array(input_point), np.array(input_label)\n",
    "    \n",
    "    def sample(self, mode, border_mode, mask_of_blobs: np.ndarray, mask: np.ndarray):\n",
    "        if mode==\"A\":\n",
    "            return self.sample_pixels(mask_of_blobs, mask)\n",
    "        elif mode==\"B\":\n",
    "            return self.sample_pixels_center_of_mass(mask_of_blobs, mask)\n",
    "        elif mode==\"C\":\n",
    "            return self.sample_pixels_random(mask_of_blobs, mask)\n",
    "        elif mode==\"D\":\n",
    "            if border_mode==\"on\":\n",
    "                return self.sample_pixels_eroded_grid(mask_of_blobs, mask)\n",
    "            else:\n",
    "                return self.sample_pixels_grid(mask_of_blobs, mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ce126d-bba7-4ba7-bed7-4bee9e3ee36c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters of the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e61ba-857e-4283-a825-e7b1fba36993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "verbose           = False\n",
    "\n",
    "## Data settings\n",
    "dataset_path     =  ## Put your PATH here!\n",
    "base_output_path =  ## Put your PATH here!\n",
    "\n",
    "def get_complete_output_path(bop, dataset_name, src_msk, model, create=False):\n",
    "    results_dir = os.path.join(bop, dataset_name, src_msk, model)\n",
    "    if create:\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "    return results_dir\n",
    "\n",
    "def get_min_blob_number_based_on_dataset(dataset):\n",
    "    return 20 if dataset==\"portrait\" else 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ea1354-1c15-470f-9881-dc9358193d92",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check datasets health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a76a152-ae94-44eb-9816-601ebf09ab39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = [\"CAMO\", \"Portrait\", \"Locuste\", \"Ribs\", \\\n",
    "            \"SKIN/SKIN_COMPAQ\", \"SKIN/SKIN_ECU\", \"SKIN/SKIN_HANDGESTURE\", \"SKIN/SKIN_MCG\", \\\n",
    "            \"SKIN/SKIN_Pratheepan\", \"SKIN/SKIN_Schmugge\", \"SKIN/SKIN_SFA\", \\\n",
    "            \"SKIN/SKIN_uchile\", \"SKIN/SKIN_VMD\", \"SKIN/SKIN_VT-AAST\", \\\n",
    "            \"Butterfly/FoldDA1_1\", \"Butterfly/FoldDA1_2\", \"Butterfly/FoldDA1_3\", \"Butterfly/FoldDA1_4\", \\\n",
    "            \"COCO_val2017\"]\n",
    "\n",
    "max_length = len(max(datasets, key=len))\n",
    "\n",
    "for dataset in datasets:\n",
    "    path = os.path.join(dataset_path, dataset)\n",
    "    \n",
    "    # 1. check \"imgs\" exists and count files in it\n",
    "    # if not, print a big warning (imgs does not exists)\n",
    "    # 2. check   \"gt\" exists and count files in it\n",
    "    # if not, print a big warning (gt does not exists)\n",
    "    # get all directories starting with \"segmentator_\"\n",
    "    #   for each, count files in it\n",
    "    # if empty: print warning (no segmentator -> only oracle is available)\n",
    "    \n",
    "    imgs_num = gt_num = 0\n",
    "    segm_num = {}\n",
    "    \n",
    "    imgs_exists = os.path.isdir(os.path.join(path, \"imgs\"))\n",
    "    gt_exists   = os.path.isdir(os.path.join(path, \"gt\"))\n",
    "    segmentators = glob.glob(os.path.join(path, \"segmentator_*\"))\n",
    "    \n",
    "    if imgs_exists:\n",
    "        imgs_num = len(glob.glob(os.path.join(path, \"imgs\", \"*\")))\n",
    "    \n",
    "    if gt_exists:\n",
    "        gt_num = len(glob.glob(os.path.join(path, \"gt\", \"*\")))\n",
    "    \n",
    "    print(f\"{dataset.ljust(max_length)} | {imgs_num:8d} | {gt_num:8d}\", end=\"\", flush=True)\n",
    "    \n",
    "    for idx, segmentator in enumerate(segmentators):\n",
    "        num = len(glob.glob(os.path.join(segmentator, \"*.bmp\")))\n",
    "        print(f\" - {os.path.basename(segmentator)[12:]} ({num})\", end=\"\", flush=True)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c324b4-e257-489b-a14c-04612588f5d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loadpaths(dataset_path, dataset_name, segmentator_name):\n",
    "    \n",
    "    if not os.path.isdir(os.path.join(dataset_path, dataset_name)):\n",
    "        print(\"ERROR. provided dataset does not exist!\")\n",
    "        return None\n",
    "    \n",
    "    orig_images_folder = os.path.join(dataset_path, dataset_name, \"imgs\")\n",
    "    gt_folder          = os.path.join(dataset_path, dataset_name, \"gt\")\n",
    "    segmentator_folder = os.path.join(dataset_path, dataset_name, \"segmentator_\" + segmentator_name)\n",
    "    \n",
    "    ## Load input images ##\n",
    "    test_imgs = glob.glob(os.path.join(orig_images_folder, '*'))\n",
    "    bn = [os.path.basename(path[:-4]).zfill(6) for path in test_imgs]\n",
    "    test_imgs = [test_imgs[i] for i in sorted(range(len(bn)), key=lambda k: bn[k])]\n",
    "    \n",
    "    ## Load GT masks ##\n",
    "    gt_masks = glob.glob(os.path.join(gt_folder, '*'))\n",
    "    bn = [os.path.basename(path[:-4]).zfill(6) for path in gt_masks]\n",
    "    gt_masks = [gt_masks[i] for i in sorted(range(len(bn)), key=lambda k: bn[k])]\n",
    "    \n",
    "    print(os.path.join(segmentator_folder, '*.bmp'))\n",
    "\n",
    "    ## Load DeepLabV3+ produced binary masks ##\n",
    "    segmentator_bmasks = glob.glob(os.path.join(segmentator_folder, '*.bmp'))\n",
    "    bn = [os.path.basename(path[:-4]).zfill(6) for path in segmentator_bmasks]\n",
    "    segmentator_bmasks = [segmentator_bmasks[i] for i in sorted(range(len(bn)), key=lambda k: bn[k])]\n",
    "\n",
    "    # ## Load DeepLabV3+ produced 3D masks ##\n",
    "    segmentator_rmasks = glob.glob(os.path.join(segmentator_folder, '*.png'))\n",
    "    bn = [os.path.basename(path[:-4]).zfill(6) for path in segmentator_rmasks]\n",
    "    segmentator_rmasks = [segmentator_rmasks[i] for i in sorted(range(len(bn)), key=lambda k: bn[k])]\n",
    "        \n",
    "    return test_imgs, gt_masks, segmentator_bmasks, segmentator_rmasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa58c87-c503-4019-ae47-2639a514627d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765e952",
   "metadata": {
    "tags": []
   },
   "source": [
    "Predict with `SamPredictor.predict`. The model returns\n",
    " - masks  (`masks.shape  # (number_of_masks) x H x W) ` )\n",
    " - quality predictions for those masks\n",
    " - low resolution mask logits that can be passed to the next iteration of prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0e938",
   "metadata": {
    "tags": []
   },
   "source": [
    "The `predict()` function accepts three parameters (among many):\n",
    "\n",
    " - `point_coords`: an np.ndarray of 2D pixels that will provide SAM the checkpoints/seeds of the object to segment\n",
    " - `point_labels`: is the corresponding pixel a pixel belonging to the object (1) or not (0) ?\n",
    "\n",
    " - With `multimask_output=True` (the default setting), SAM outputs 3 masks, where `scores` gives the model's own estimation of the quality of these masks. This setting is intended for ambiguous input prompts, and helps the model disambiguate different objects consistent with the prompt. When `False`, it will return a single mask. For ambiguous prompts such as a single point, it is recommended to use `multimask_output=True` even if only a single mask is desired; the best single mask can be chosen by picking the one with the highest score returned in `scores`. This will often result in a better mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bde0a0-6c4f-4799-af95-eb50ab212758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perform(predictor, model_type, source_mask, dataset, points_sampling_mode, sampling_step, border_mode):\n",
    "    global verbose\n",
    "    \n",
    "    print(model_type, source_mask, dataset, points_sampling_mode, sampling_step, border_mode) \n",
    "    \n",
    "    min_blob_count = get_min_blob_number_based_on_dataset(dataset)\n",
    "    \n",
    "    test_imgs, gt_masks, src_bmasks, src_rmasks = loadpaths(dataset_path, dataset, source_mask)\n",
    "    \n",
    "    if source_mask==\"oracle\":\n",
    "        assert len(test_imgs) == len(gt_masks),\\\n",
    "                  f\"unbalanced datasets! {len(test_imgs)} {len(gt_masks)}\"\n",
    "        src_bmasks = src_rmasks = gt_masks\n",
    "    else:\n",
    "        assert len(test_imgs) == len(gt_masks) == len(src_bmasks) == len(src_rmasks),\\\n",
    "                  f\"unbalanced datasets! {len(test_imgs)} {len(gt_masks)} {len(src_rmasks)}\"\n",
    "    \n",
    "    toiterate = zip(test_imgs, gt_masks, src_bmasks, src_rmasks)\n",
    "\n",
    "    print(\"len of files:\", len(test_imgs)) if verbose else None\n",
    "    \n",
    "    possampler = Sampler(verbose, sampling_step, min_blob_count)\n",
    "    \n",
    "    results_dir = get_complete_output_path(base_output_path, dataset, source_mask, model_type, create=True)\n",
    "    \n",
    "    print(\"results will be saved at for results_dir\", results_dir)\n",
    "    \n",
    "    metrics, source_mask_metrics, metrics_fusion = Metrics(dataset), Metrics(dataset), Metrics(dataset)\n",
    "    \n",
    "    for idx, paths in tqdm(enumerate(toiterate), total=len(test_imgs)):\n",
    "        print(f\" - img idx {str(idx+1).zfill(6)}/{len(test_imgs)}:\") if verbose else None\n",
    "        \n",
    "        # Get paths\n",
    "        img_path, gt_mask_path, src_bmask_path, src_rmask_path = paths\n",
    "        log(paths) if verbose else None\n",
    "        \n",
    "        # Load images from disk using paths\n",
    "        img           = read_img(img_path)\n",
    "        gt_mask       = read_bmask(gt_mask_path)\n",
    "        src_bmask = read_bmask(src_bmask_path)\n",
    "        src_rmask = read_rmask(src_rmask_path)\n",
    "        \n",
    "        if source_mask==\"oracle\":\n",
    "            assert img.shape[:2] == gt_mask.shape, f\"Error: shape mismatch {img.shape[:2]} {gt_mask.shape}\"\n",
    "        else:\n",
    "            assert img.shape[:2] == gt_mask.shape == \\\n",
    "                src_bmask.shape == src_rmask.shape[:2], f\"Error: shape mismatch {img.shape[:2]} {gt_mask.shape} {src_bmask.shape} {src_rmask.shape[:2]}\"\n",
    "        \n",
    "        if source_mask==\"oracle\":\n",
    "            mask_to_sample = gt_mask\n",
    "        else:\n",
    "            mask_to_sample = src_bmask\n",
    "\n",
    "        # Count the number of distinct labels (it corresponds to the number of blobs)\n",
    "        mask_of_blobs = get_mask_of_blobs(mask_to_sample)\n",
    "        \n",
    "        # Sample the checkpoints (at least one for blob)\n",
    "        unique_blobs = np.unique(mask_of_blobs)\n",
    "        num_blobs = unique_blobs.shape[0]\n",
    "        if num_blobs==1 and 0 in unique_blobs:\n",
    "            print(\"unique blob\")\n",
    "            input_point = input_label= np.array([])\n",
    "            binary_mask = np.zeros_like(mask_to_sample)\n",
    "            masks=[binary_mask]\n",
    "            best_score_idx=0\n",
    "        else:\n",
    "            \n",
    "            input_point, input_label = possampler.sample(points_sampling_mode, border_mode, mask_of_blobs, mask_to_sample.astype(np.int64))\n",
    "            \n",
    "            print(\"setting image on predictor\", end=\"... \")  if verbose else None\n",
    "            predictor.set_image(img)\n",
    "\n",
    "            print(\"predicting\", end=\"... \")  if verbose else None\n",
    "            masks, scores, logits = predictor.predict(\n",
    "                point_coords=input_point,\n",
    "                point_labels=input_label,\n",
    "                multimask_output=False,\n",
    "                return_logits=True\n",
    "            )\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            best_score_idx = np.argmax(scores)\n",
    "            binary_mask = masks[best_score_idx] > 0\n",
    "            \n",
    "            metrics.step(binary_mask, gt_mask)\n",
    "        \n",
    "        source_mask_metrics.step(src_bmask, gt_mask)\n",
    "        \n",
    "        # instead of saving and then loading images, we can use this script to simulate the storage of .jpg images\n",
    "        success, encoded_image = cv2.imencode(\".jpg\",  masks[best_score_idx]*255)\n",
    "        if success:\n",
    "            jpeg_data = np.array(encoded_image).tobytes()\n",
    "        else:\n",
    "            print(\"Failed to encode the image as JPEG.\")\n",
    "        decoded_image = cv2.imdecode(encoded_image, cv2.IMREAD_COLOR)[:, :, 0]\n",
    "        \n",
    "        ## this is how we saved the produced masks\n",
    "        # basename = os.path.basename(img_path)\n",
    "        # out_mask_path = results_dir + \"/\" + basename[:basename.rfind(\".\")+1]+\"jpg\"\n",
    "        # cv2.imwrite(out_mask_path, masks[best_score_idx]*255)\n",
    "        \n",
    "        ## this is how we loaded .jpg images\n",
    "        # basename = os.path.basename(img_path)\n",
    "        # in_mask_path = results_dir + \"/\" + basename[:basename.rfind(\".\")+1]+\"jpg\"\n",
    "        # decoded_image = cv2.imread(in_mask_path)[:, :, 0]\n",
    "        \n",
    "        src_rmask = read_bmask(src_rmask_path).astype(np.float64) * 255\n",
    "        fused_mask = abs(255 - decoded_image.astype('uint8'))\n",
    "        fused_mask = ((fused_mask + 2*src_rmask)/3).astype(np.uint8) < 128\n",
    "        metrics_fusion.step(fused_mask, gt_mask)\n",
    "        \n",
    "        ## TO VISUALIZE computed mask, show the superposition with the original image\n",
    "        ## and SAM's predicted score and IoU wrt Ground Truth mask\n",
    "        # plt.clf()\n",
    "        # fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(30, 30))\n",
    "        # axes[0].imshow(img)\n",
    "        # if input_point.shape[0]>0:\n",
    "        #     axes[0].scatter([input_point[:, 0]], [input_point[:, 1]], color='red', marker='*', s=250, edgecolor='white', linewidth=1.25) # this is if you want the star\n",
    "        # axes[1].imshow(gt_mask)\n",
    "        # axes[2].imshow(binary_mask)\n",
    "        # # axes[3].imshow(fused_mask)\n",
    "        # fig.tight_layout()\n",
    "        # plt.show()\n",
    "        # break\n",
    "        \n",
    "    \n",
    "    iou_avg, dice_avg, mae_avg, wfm_avg, eme_avg  = metrics.get_results()\n",
    "    \n",
    "    print(\"SAM alone metrics:\")\n",
    "    print(f\"average iou      : {iou_avg*100:5.2f}\")\n",
    "    print(f\"average dice     : {dice_avg*100:5.2f}\")\n",
    "    print()\n",
    "    \n",
    "    iou_avg, dice_avg, mae_avg, wfm_avg, eme_avg  = source_mask_metrics.get_results()\n",
    "    print(f\"segmentator_{source_mask} metrics:\")\n",
    "    print(f\"average iou      : {iou_avg*100:5.2f}\")\n",
    "    print(f\"average dice     : {dice_avg*100:5.2f}\")\n",
    "    print()\n",
    "    \n",
    "    iou_avg, dice_avg, mae_avg, wfm_avg, eme_avg  = metrics_fusion.get_results()\n",
    "    print(\"SAM-fusion performance:\")\n",
    "    print(f\"average iou      : {iou_avg*100:5.2f}\")\n",
    "    print(f\"average dice     : {dice_avg*100:5.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf1d58-f8c3-4798-813c-c7072901a8f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perform_all(dataset_name, predictor, model_type, source_mask):\n",
    "    # perform(predictor, model_type, source_mask, dataset_name, \"A\", None, None)\n",
    "    # perform(predictor, model_type, source_mask, dataset_name, \"B\", None, None)\n",
    "    # perform(predictor, model_type, source_mask, dataset_name, \"C\", None, None)\n",
    "    # perform(predictor, model_type, source_mask, dataset_name, \"D\", 10, \"on\")\n",
    "    # perform(predictor, model_type, source_mask, dataset_name, \"D\", 30, \"on\")\n",
    "    # perform(predictor, model_type, source_mask, dataset_name, \"D\", 50, \"on\")\n",
    "    # perform(predictor, model_type, source_mask, dataset_name, \"D\", 100, \"on\")\n",
    "    # perform(predictor, model_type, source_mask, dataset_name, \"D\", 10, \"off\")\n",
    "    # perform(predictor, model_type, source_mask, dataset_name, \"D\", 30, \"off\")\n",
    "    perform(predictor, model_type, source_mask, dataset_name, \"D\", 50, \"off\")\n",
    "    # perform(predictor, model_type, source_mask, dataset_name, \"D\", 100, \"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de05606-e970-45cd-9aa7-3e440226a16e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## USE VIT-L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536fee45-6e99-451f-b8c4-b0f64c3be0ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = \"cuda\" # [\"cuda\", \"cpu\"]\n",
    "# sam_checkpoint = os.path.join(\"/home/fusaro/segment-anything/\", \"pretrained_models\", \"sam_vit_l_0b3195.pth\")\n",
    "# model_type = \"vit_l\"\n",
    "# source_mask = \"deeplab\" # [\"oracle\", \"deeplab\", \"pvtv2\", \"sota\"] ### it depends, choose as needed!\n",
    "# verbose=False\n",
    "\n",
    "# print(f\"creating sam {model_type} and moving it to device\")\n",
    "# sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "# sam.to(device=device)\n",
    "# print(\"creating predictor\")\n",
    "# predictor = SamPredictor(sam)  \n",
    "\n",
    "\n",
    "# # CHOOSE ONE (OR MANY)\n",
    "# datasets = []\n",
    "# # datasets.append(\"CAMO\")\n",
    "# # datasets.append(\"Portrait\")\n",
    "# datasets.append(\"Locuste\")\n",
    "# # datasets.append(\"Ribs\")\n",
    "# # datasets.append(\"SKIN/SKIN_COMPAQ\")\n",
    "# # datasets.append(\"SKIN/SKIN_ECU\")\n",
    "# # datasets.append(\"SKIN/SKIN_HANDGESTURE\")\n",
    "# # datasets.append(\"SKIN/SKIN_MCG\")\n",
    "# # datasets.append(\"SKIN/SKIN_Pratheepan\")\n",
    "# # datasets.append(\"SKIN/SKIN_Schmugge\")\n",
    "# # datasets.append(\"SKIN/SKIN_SFA\")\n",
    "# # datasets.append(\"SKIN/SKIN_uchile\")\n",
    "# # datasets.append(\"SKIN/SKIN_VMD\")\n",
    "# # datasets.append(\"SKIN/SKIN_VT-AAST)\n",
    "# # datasets.append(\"Butterfly/FoldDA1_1\")\n",
    "# # datasets.append(\"Butterfly/FoldDA1_2\")\n",
    "# # datasets.append(\"Butterfly/FoldDA1_3\")\n",
    "# # datasets.append(\"Butterfly/FoldDA1_4\")\n",
    "# # datasets.append(\"COCO_val2017\")\n",
    "\n",
    "# for dataset in datasets:\n",
    "#     perform_all(dataset, predictor, model_type, source_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d9840-a7f5-4312-b755-a6fd54b10814",
   "metadata": {
    "tags": []
   },
   "source": [
    "## USE VIT-H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54a09c-5dcb-4f97-886e-7981249eb906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" # [\"cuda\", \"cpu\"]\n",
    "verbose = False\n",
    "sam_checkpoint = os.path.join(\"/home/fusaro/segment-anything/\", \"pretrained_models\", \"sam_vit_h_4b8939.pth\")\n",
    "model_type = \"default\"\n",
    "source_mask = \"deeplab\" # [\"oracle\", \"deeplab\", \"pvtv2\", \"sota\"] ### it depends, choose as needed!\n",
    "\n",
    "# print(f\"creating sam {model_type} and moving it to device\")\n",
    "# sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "# sam.to(device=device)\n",
    "# print(\"creating predictor\")\n",
    "# predictor = SamPredictor(sam)  \n",
    "\n",
    "# CHOOSE ONE (OR MANY)\n",
    "datasets = []\n",
    "# datasets.append(\"CAMO\")\n",
    "# datasets.append(\"Portrait\")\n",
    "# datasets.append(\"Locuste\")\n",
    "# datasets.append(\"Ribs\")\n",
    "# datasets.append(\"SKIN/SKIN_COMPAQ\")\n",
    "# datasets.append(\"SKIN/SKIN_ECU\")\n",
    "# datasets.append(\"SKIN/SKIN_HANDGESTURE\")\n",
    "# datasets.append(\"SKIN/SKIN_MCG\")\n",
    "# datasets.append(\"SKIN/SKIN_Pratheepan\")\n",
    "# datasets.append(\"SKIN/SKIN_Schmugge\")\n",
    "# datasets.append(\"SKIN/SKIN_SFA\")\n",
    "# datasets.append(\"SKIN/SKIN_uchile\")\n",
    "# datasets.append(\"SKIN/SKIN_VMD\")\n",
    "# datasets.append(\"SKIN/SKIN_VT-AAST\")\n",
    "# datasets.append(\"Butterfly/FoldDA1_1\")\n",
    "# datasets.append(\"Butterfly/FoldDA1_2\")\n",
    "# datasets.append(\"Butterfly/FoldDA1_3\")\n",
    "datasets.append(\"Butterfly/FoldDA1_4\")\n",
    "# datasets.append(\"COCO_val2017\")\n",
    "\n",
    "for dataset in datasets:\n",
    "    perform_all(dataset, predictor, model_type, source_mask)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
